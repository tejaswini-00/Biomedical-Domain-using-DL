									Abstract					
As biomedical information in the form of publications and electronic health records (EHR)														
increases	at	an	increasingly	fast	pace,	there	is	clear	utility	in	having sys- tems	that	can	
automatically handle information extraction, summarization, and question answering tasks.														
While there have been significant strides in improving language tasks for general language,														
addressing domain-specific contexts still remains challenging. In this project, I apply and														
fine-tune models to the SQuAD dataset and further modify/adapt for biomedical domain-														
specific question answer- ing.	I			evaluated		and compared		performance		on	the	SQuAD		
dataset and BioASQ, a biomedical				literature QA dataset, with the goal of analyzing and										
developing	approaches to leverage unsupervised language models for domain-specific													
applica- tions. Upon generating various fine-tuned models, the best performance for general														
language SQuAD			QA	achieved an F1	score of 76.717, EM			score of 73.379, and for						
biomedical-specific BioASQ QA achieved an F1 score of 70.348 and EM score of 49.902.														
1	Introduction													
Machine comprehension tasks have become increasingly important as the amount														
of	content		and	information	being	generated	is	scaling	at	an	unprecedented	rate.		
Question		Answering	(QA)	is	a	task	that	has	seen	accelerated	performance			
improvement			with	the	availability	of	Stanford’s	Ques- tion	Answering		dataset			
(SQuAD)		that	includes	more	than	150,000	question-answer		pairs	and	their			
corresponding			context	paragraphs	from	Wikipedia		[1].	In	just	the	recent	year,	
performance of QA tasks among				many other natural				language processing (NLP)						
tasks	encountered		a	major	boost	by	the	advent	of	pre-trained	contextual			
embeddings		(PCE).	The	objective	of	PCE	is	to	generate	word	embeddings	that		
depend on the context in which the word appears in the text opposed to traditional														
word embeddings such as Word2Vec where each word in the vocabulary is mapped														
to a fixed vector, regardless of context. PCEs are built by pretraining weights on a														
large-scale language modeling dataset, then loading the pretrained weights into a														
model.														
While there have been significant strides in improving language tasks for general														
language, addressing			domain-specific			contexts	still	remains	challenging.		In	the		
scientific biomedical field, the output of publications is estimated to double every														
5-10	years,		currently	with	more	than	3000	new	articles	published	per day.			
However, in			contrast	to	general	QA,	it	is	challenging	to	generate	a	biomedical	
domain-specific QA dataset comparable to the scale of SQuAD. In this project, I														
aim to leverage general QA language models for transfer learning of biomedical														
domain-specific applications.														
Biomedical informatics has been an “emerging field” for decades. Concern about medical														
information and the desire to computerize health care are hardly									new. Though originally					
focused	on	traditional	paper-based		medical	records		and	their	management	rather	than		
electronic	medical		records,	the	American	Health	Information		Management		Association			
(AHIMA)	was	founded	in	1928	as	the	American	Association	of	Medical	Record			
Librarians[1].		Papers	about	medical	reasoning		were	published	in	the	1950’s	[2].	Kaiser	
Permanente established a department of medical methods research in September of 1961;														
one of its goals was to “begin to use computers in the practice of medicine” [3]. In 1962,														
they	obtained	their	first	federal	grants	to	automate	and	improve		screening	methods	[4].	
Recent	developments		have	thrust	informatics	into		the	national	spotlight	as	part	of	a
massive economic stimulus package known as the American Recovery and Reinvestment														
Act.														
